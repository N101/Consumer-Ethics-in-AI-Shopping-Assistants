{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c3040a25e413395",
   "metadata": {},
   "source": [
    "## Task 1: Scoring & comparing LLMs on CES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcc0384c4ae9ef",
   "metadata": {},
   "source": [
    "Step 1: connecting to GPT via API ✅ \\\n",
    "Step 2: create prompt to correctly get response to questions ✅ \\\n",
    "Step 3: connecting to GPT via API ✅ \\\n",
    "Step 4: prompt engineering to get response in desired format (collectable & ready for analysis) ✅ \\\n",
    "Step 5: saving results to .csv file ✅ \\\n",
    "Step 6: repeat multiple times ✅ \\\n",
    "Step 7: create pipeline to automate process ✅   \n",
    "   - input current CES question \n",
    "   - result is stored in .csv file in correct format  \n",
    "   - run 50/100 times  \n",
    "   - get average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T19:00:32.000073Z",
     "start_time": "2024-11-05T19:00:26.852891Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from openai import OpenAI, api_key\n",
    "from anthropic import Anthropic\n",
    "from google.generativeai import GenerativeModel, configure\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b94fdd0855dd639",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T19:00:39.861399Z",
     "start_time": "2024-11-05T19:00:39.459538Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'context' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# client = Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])\u001b[39;00m\n\u001b[1;32m      5\u001b[0m configure(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEMINI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m client_gemini \u001b[38;5;241m=\u001b[39m GenerativeModel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-flash\u001b[39m\u001b[38;5;124m\"\u001b[39m, system_instruction\u001b[38;5;241m=\u001b[39m\u001b[43mcontext\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'context' is not defined"
     ]
    }
   ],
   "source": [
    "#setting API Key\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY_HfP'])\n",
    "# client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "# client = Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])\n",
    "configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "client_gemini = GenerativeModel(\"gemini-1.5-flash\", system_instruction=context[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572b5748e60e43f",
   "metadata": {},
   "source": [
    "testing response from model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b908d86ae26ca89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:11:49.464906Z",
     "start_time": "2024-11-03T11:11:48.531757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# response = client.completions.create(     # old GPT version for text completions (only single prompts)\n",
    "response = client.chat.completions.create(      # GPT \n",
    "# response = client.messages.create(              # Claude\n",
    "#     model=\"claude-3-5-sonnet-20240620\", \n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.9,\n",
    "    messages=[context, {\"role\":\"user\", \"content\":  questions[0]}],\n",
    "    max_tokens=2048\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "# response = client.generate_content(questions[0])    # Gemini\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402735ce4967b005",
   "metadata": {},
   "source": [
    "extracting questions from an md file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a393b6fe89d5bf09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T19:00:43.282706Z",
     "start_time": "2024-11-05T19:00:43.277293Z"
    }
   },
   "outputs": [],
   "source": [
    "# returns **list** of all questions extracted from the file\n",
    "def extract_question(path, r):\n",
    "    matches = []\n",
    "    with open(path) as f:\n",
    "        # print(f.read())\n",
    "        for line in f:\n",
    "            # print(line)\n",
    "            if ma:=re.match(r, line, re.MULTILINE):\n",
    "                # print(\"matched:\")\n",
    "                # print(line)\n",
    "                # print(ma.group(1))\n",
    "                # print(f\"groups: {ma.groups()}\")\n",
    "                matches.append(ma.group(1).rstrip('\\n'))\n",
    "    \n",
    "    return matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a879989fd26f52f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T20:48:49.075121Z",
     "start_time": "2024-11-05T20:48:49.062948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting...\n",
      "---finished extracting.\n",
      "Question 1: Returning damaged goods when the damage was your own fault \n",
      "\n",
      "Question 2: Giving misleading price information to a clerk for an unpriced item \n",
      "\n",
      "Question 3: Using a long distance access code that does not belong to you \n",
      "\n",
      "Question 4: Drinking a can of soda in a store without paying for it \n",
      "\n",
      "Question 5: Reporting a lost item as \"stolen\" to an insurance company in order to collect the insurance money\n",
      "\n",
      "Question 6: Moving into a residence, finding that the cable TV is still hooked up, and using it without paying for it \n",
      "\n",
      "Question 7: Lying about a child's age to get a lower price \n",
      "\n",
      "Question 8: Not saying anything when the waiter or waitress miscalculates a bill in your favor \n",
      "\n",
      "Question 9: Getting too much change and not saying anything \n",
      "\n",
      "Question 10: Joining a CD club just to get some free CD's with no intention of buying any \n",
      "\n",
      "Question 11: Observing someone shoplifting and ignoring it\n",
      "\n",
      "Question 12: Using an expired coupon for merchandise \n",
      "\n",
      "Question 13: Returning merchandise to a store by claiming that it was a gift when it was not \n",
      "\n",
      "Question 14: Using a coupon for merchandise you did not buy \n",
      "\n",
      "Question 15: Not telling the truth when negotiating the price of a new automobile \n",
      "\n",
      "Question 16: Stretching the truth on an income tax return\n",
      "\n",
      "Question 17: Installing software on your computer without buying it\n",
      "\n",
      "Question 18: \"Burning\" a CD rather than buying it \n",
      "\n",
      "Question 19: Returning merchandise after buying it and not liking it \n",
      "\n",
      "Question 20: Taping a movie off the television \n",
      "\n",
      "Question 21: Spending over an hour trying on clothing and not buying anything\n",
      "\n",
      "Question 22: Downloading music from the internet instead of buying it \n",
      "\n",
      "Question 23: Buying counterfeit goods instead of buying the original manufacturers' brands\n",
      "\n",
      "Question 24: Buying products labeled as \"environmentally friendly\" even if they don't work as well as competition products \n",
      "\n",
      "Question 25: Purchasing something made of recycled materials even though it is more expensive \n",
      "\n",
      "Question 26: Buying only from companies that have a strong record of protecting the environment \n",
      "\n",
      "Question 27: Recycling materials such as cans, bottles, newspapers, etc.\n",
      "\n",
      "Question 28: Returning to the store and paying for an item that the cashier mistakenly did not charge you for \n",
      "\n",
      "Question 29: Correcting a bill that has been miscalculated in your favor \n",
      "\n",
      "Question 30: Giving a larger than expected tip to a waiter or waitress \n",
      "\n",
      "Question 31: Not purchasing products from companies that you believe don't treat their employees fairly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "re_context_question = r'.*Contextualized version\\*\\*:\\s*\"([^\"]+)\"'\n",
    "# re_typed_questions = r'^- (.+)$'\n",
    "re_typed_questions = r'^\\d+\\. (.+)'\n",
    "\n",
    "path = \"CES_questionnaire.md\"\n",
    "# path = \"misc/typed_CES_questions.md\"\n",
    "\n",
    "print(\"extracting...\")\n",
    "questions = extract_question(path, re_typed_questions)\n",
    "print(\"---finished extracting.\")\n",
    "# for i, q in enumerate(questions, 1):\n",
    "#     print(f\"Question {i}: {q}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84dbd55b9237a8",
   "metadata": {},
   "source": [
    "Answering entire set of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779c9e7fc0f8b700",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:11:15.783205Z",
     "start_time": "2024-11-03T11:11:15.773686Z"
    }
   },
   "outputs": [],
   "source": [
    "context_reasoning = {\"role\":\"system\", \"content\": \"\"\"\n",
    "You will be asked a series of questions which you are to answer on a Likert scale, from 1 to 5, with 1 = 'Strongly Disagree', 2 = 'Disagree', 3 = 'Neutral', 4 = 'Agree', 5 = 'Strongly Agree'. \n",
    "Format your answer as following: \n",
    "- First, simply state your answer on the scale (as a number). \n",
    "- Then, state your reasoning.\n",
    "\n",
    "Examples: \n",
    "    Question: \"While shopping at a large retail store, you notice that no one is around. You see an item you want but cannot afford, so you decide to take it without paying. How acceptable is this behavior?\"\n",
    "\n",
    "    Answer: # Do not include this line in your response, this is simply for your understanding to ensure the question and answer aspects of the examples are clearly separated.\n",
    "    5\n",
    "    Taking an item without paying is generally considered theft and is not acceptable behavior.\n",
    "\n",
    "    Question: \"You buy an item online but when it arrives you see the package has been roughed up during the travel and the item doesn't work as it is supposed to. You send the product back and demand a refund for the faulty item. How acceptable is this behavior?\n",
    "\n",
    "    4\n",
    "    It is generally considered acceptable to return a faulty item and request for a refund.\n",
    "\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca9b9526e900468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:11:16.355574Z",
     "start_time": "2024-11-03T11:11:16.350567Z"
    }
   },
   "outputs": [],
   "source": [
    "# no reasoning included\n",
    "context = {\"role\": \"system\", \"content\": \"\"\"\n",
    "You will be asked a series of questions which you are to answer on a Likert scale, from 1 to 5, with 1 = 'Strongly Disagree', 2 = 'Disagree', 3 = 'Neutral', 4 = 'Agree', 5 = 'Strongly Agree'.\n",
    "Format your answer as following:\n",
    "- Simply state your answer on the scale (as a number). Nothing more, nothing less. Just simply a single digit answer.\n",
    "\n",
    "Examples:\n",
    "Question: \"While shopping at a large retail store, you notice that no one is around. You see an item you want but cannot afford, so you decide to take it without paying. How acceptable is this behavior?\"\n",
    "\n",
    "5\n",
    "\n",
    "Question: \"You buy an item online but when it arrives you see the package has been roughed up during the travel and the item doesn't work as it is supposed to. You send the product back and demand a refund for the faulty item. How acceptable is this behavior?\n",
    "\n",
    "4\n",
    "\"\"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c6a155d875ce93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T22:28:19.291828Z",
     "start_time": "2024-09-24T22:28:02.823711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer for question 1: 1 \n",
      "\n",
      "Answer for question 2: 1 \n",
      "\n",
      "Answer for question 3: 2 \n",
      "\n",
      "Answer for question 4: 1 \n",
      "\n",
      "Answer for question 5: 1 \n",
      "\n",
      "Answer for question 6: 2 \n",
      "\n",
      "Answer for question 7: 3 \n",
      "\n",
      "Answer for question 8: 3 \n",
      "\n",
      "Answer for question 9: 2 \n",
      "\n",
      "Answer for question 10: 2 \n",
      "\n",
      "Answer for question 11: 2 \n",
      "\n",
      "Answer for question 12: 2 \n",
      "\n",
      "Answer for question 13: 2 \n",
      "\n",
      "Answer for question 14: 1 \n",
      "\n",
      "Answer for question 15: 1 \n",
      "\n",
      "Answer for question 16: 3 \n",
      "\n",
      "Answer for question 17: 3 \n",
      "\n",
      "Answer for question 18: 2 \n",
      "\n",
      "Answer for question 19: 3 \n",
      "\n",
      "Answer for question 20: 2 \n",
      "\n",
      "Answer for question 21: 2 \n",
      "\n",
      "Answer for question 22: 2 \n",
      "\n",
      "Answer for question 23: 2 \n",
      "\n",
      "Answer for question 24: 2 \n",
      "\n",
      "Answer for question 25: 2 \n",
      "\n",
      "Answer for question 26: 2 \n",
      "\n",
      "Answer for question 27: 3 \n",
      "\n",
      "Answer for question 28: 2 \n",
      "\n",
      "Answer for question 29: 2 \n",
      "\n",
      "Answer for question 30: 3 \n",
      "\n",
      "Answer for question 31: 4 \n",
      "\n",
      "Answer for question 32: 5 \n",
      "\n",
      "Answer for question 33: 5 \n",
      "\n",
      "Answer for question 34: 5 \n",
      "\n",
      "Answer for question 35: 5 \n",
      "\n",
      "Answer for question 36: 5 \n",
      "\n",
      "Answer for question 37: 5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying to reduce overhead\n",
    "for i, q in enumerate(questions, 1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0.9,\n",
    "        messages=[context, {\"role\":\"user\", \"content\": q}]\n",
    "    )\n",
    "    print(f\"Answer for question {i}: \", end=\"\")\n",
    "    print(response.choices[0].message.content , \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ca8b6e872e03b",
   "metadata": {},
   "source": [
    "saving to .csv file \n",
    "\n",
    "**format of csv file:**  \n",
    "| **questions**  | itr_num | answer |\n",
    "|----------------|---------|--------|\n",
    "| \"*question 1*\" | itr_num | answer |\n",
    "|                | itr_num | answer |\n",
    "| \"*question 2*\" | itr_num | answer |\n",
    "|                | itr_num | answer |\n",
    "\n",
    "group iterations by question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b2ad8d1768b658c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T10:34:31.267707Z",
     "start_time": "2024-10-08T10:34:31.217155Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating dataframe for that format\n",
    "df = pd.DataFrame(columns=[\"questions\", \"iteration\", \"answer\"])\n",
    "# df = pd.DataFrame(columns=[\"questions\", \"answer\", \"reasoning\"])\n",
    "data_list = [[]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3483515f5c9e28d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:13:05.868067Z",
     "start_time": "2024-11-03T11:13:05.862062Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response(content: str, model=\"gpt-4o-mini\", temperature=1):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[context, {\"role\":\"user\", \"content\": content}]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc1db179273dbc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T10:32:56.316199Z",
     "start_time": "2024-10-08T10:32:56.276365Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Item(BaseModel):\n",
    "    answer: str\n",
    "    reasoning: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "359c5597a5fcde94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T12:48:14.121240Z",
     "start_time": "2024-09-23T12:48:12.730310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"answer\":\"1\",\"reasoning\":\"Taking an item without paying is theft, regardless of the circumstances. It is illegal and unethical, and it undermines the trust and integrity of the retail system.\"}\n"
     ]
    }
   ],
   "source": [
    "# structured output\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[context, {\"role\": \"user\", \"content\": questions[0]}],\n",
    "    response_format=Item\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "180af8e74f8a59dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T10:34:34.205752Z",
     "start_time": "2024-10-08T10:34:34.173171Z"
    }
   },
   "outputs": [],
   "source": [
    "# df3 = df2.groupby(\"questions\") # groupby expects an aggregation function (use for sum/avg later)\n",
    "df3 = df \n",
    "df3[\"questions\"] = df3[\"questions\"].mask(df3[\"questions\"].duplicated(), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b7c4541d450c4e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:13:45.461898Z",
     "start_time": "2024-11-03T11:13:09.559830Z"
    }
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "# looping all questions\n",
    "for i, q in enumerate(questions, 1):\n",
    "    for j in range(3):\n",
    "        response = get_response(q)\n",
    "        res_list = response.choices[0].message.content.strip()#.split(\"\\n\")\n",
    "        # res_list = response.text.strip()\n",
    "        new_entry = [i, q, j, res_list]\n",
    "        data_list.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d45b8254bc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in data_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82dcb6a648ea4e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:13:48.453216Z",
     "start_time": "2024-11-03T11:13:48.382580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>questions</th>\n",
       "      <th>iteration</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Returning damaged goods when the damage was yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Returning damaged goods when the damage was yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Returning damaged goods when the damage was yo...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Giving misleading price information to a clerk...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Giving misleading price information to a clerk...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>30</td>\n",
       "      <td>Giving a larger than expected tip to a waiter ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>30</td>\n",
       "      <td>Giving a larger than expected tip to a waiter ...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>31</td>\n",
       "      <td>Not purchasing products from companies that yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>31</td>\n",
       "      <td>Not purchasing products from companies that yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>31</td>\n",
       "      <td>Not purchasing products from companies that yo...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     #                                          questions  iteration answer\n",
       "1    1  Returning damaged goods when the damage was yo...          0      1\n",
       "2    1  Returning damaged goods when the damage was yo...          1      1\n",
       "3    1  Returning damaged goods when the damage was yo...          2      1\n",
       "4    2  Giving misleading price information to a clerk...          0      2\n",
       "5    2  Giving misleading price information to a clerk...          1      2\n",
       "..  ..                                                ...        ...    ...\n",
       "89  30  Giving a larger than expected tip to a waiter ...          1      5\n",
       "90  30  Giving a larger than expected tip to a waiter ...          2      5\n",
       "91  31  Not purchasing products from companies that yo...          0      4\n",
       "92  31  Not purchasing products from companies that yo...          1      4\n",
       "93  31  Not purchasing products from companies that yo...          2      4\n",
       "\n",
       "[93 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_check = pd.DataFrame(data_list, columns=[\"#\", \"questions\", \"answer\", \"reasoning\"])\n",
    "df_check = pd.DataFrame(data_list, columns=[\"#\", \"questions\", \"iteration\", \"answer\"])\n",
    "df_check.index += 1\n",
    "df_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d6d4f6cf63c7dfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:23:00.065630Z",
     "start_time": "2024-11-03T11:22:59.949287Z"
    }
   },
   "outputs": [],
   "source": [
    "df_check[\"answer\"] = df_check[\"answer\"].astype(\"int\")\n",
    "# df[\"answer\"] = pd.to_numeric(df[\"answer\"], errors=\"coerce\")\n",
    "grouped = df_check.groupby(\"#\")[\"answer\"].mean()\n",
    "df_check[\"averages\"] = df_check.groupby(\"#\")[\"answer\"].transform(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63bea5d092675469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T11:23:00.561403Z",
     "start_time": "2024-11-03T11:23:00.533706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#\n",
       "1    1.0\n",
       "2    2.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5    1.0\n",
       "Name: answer, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6a851320d6bc09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T10:36:52.111540Z",
     "start_time": "2024-10-08T10:36:52.090908Z"
    }
   },
   "outputs": [],
   "source": [
    "# formatting question cells to only list each question once\n",
    "df_check2 = df_check.copy()\n",
    "df_check2[[\"#\", \"questions\",  \"averages\"]] = df_check2[[\"#\", \"questions\", \"averages\"]].mask(df_check2[[\"#\", \"questions\", \"averages\"]].duplicated(), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ace5e8c2d9d54e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T16:22:09.960747Z",
     "start_time": "2024-09-22T16:22:09.937748Z"
    }
   },
   "outputs": [],
   "source": [
    "df_check2.to_csv(\"df_check2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d07f1389353265c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T10:37:24.746207Z",
     "start_time": "2024-10-08T10:37:24.728392Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating averages table \n",
    "df_grp = pd.DataFrame(grouped)\n",
    "df_grp.rename(columns={\"#\": \"#\", \"answer\":\"averages\"}, inplace=True)\n",
    "# df_grp.index = range(1, len(df_grp)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8822b5e395f6fc7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T20:29:52.738726Z",
     "start_time": "2024-09-25T20:29:52.729848Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grp.to_csv(\"df_grp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11437957da151af2",
   "metadata": {},
   "source": [
    "### Testing Parallelizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4434f8ca5a70e90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-30T16:21:59.355869Z",
     "start_time": "2024-09-30T16:21:54.878018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done step 1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute '_condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# futures = [\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     executor.submit(get_response2, i, j, q) \u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     for i, q in enumerate(questions, 1) \u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#     for j in range(10)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone step 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:222\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    220\u001b[0m fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(fs)\n\u001b[1;32m    221\u001b[0m total_futures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(fs)\n\u001b[0;32m--> 222\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_AcquireFutures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinished\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mCANCELLED_AND_NOTIFIED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFINISHED\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfinished\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:149\u001b[0m, in \u001b[0;36m_AcquireFutures.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfutures:\n\u001b[0;32m--> 149\u001b[0m         \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241m.\u001b[39macquire()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute '_condition'"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "data_list = []\n",
    "\n",
    "def get_response2(i, j, content: str, model=\"gpt-4o-mini\", temperature=0.9):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[context, {\"role\":\"user\", \"content\": content}]\n",
    "    )\n",
    "    return [i, q, j, response.choices[0].message.content.strip()]\n",
    "\n",
    "def get_response_gemini(content: str, temperature=1, max_output_tokens=256):\n",
    "    response = client.generate_content(content)\n",
    "    return response\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        for j in range(2):\n",
    "            futures = [i, q, j, executor.submit(get_response_gemini, q)]\n",
    "    # futures = [\n",
    "    #     executor.submit(get_response2, i, j, q) \n",
    "    #     for i, q in enumerate(questions, 1) \n",
    "    #     for j in range(10)\n",
    "    # ]\n",
    "    print(\"done step 1\")\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        result = future.result()\n",
    "        data_list.append(result)\n",
    "        \n",
    "# sort data_list according to first column\n",
    "data_list = sorted(data_list, key=lambda x: x[0])\n",
    "ctr = 0\n",
    "index = 0\n",
    "for i, item in enumerate(data_list): \n",
    "    # if ctr > 9:\n",
    "#         ctr = 0\n",
    "#         index += 1\n",
    "#     data_list[i][1] = questions[index]\n",
    "#     ctr += 1\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57addaa08f82e85e",
   "metadata": {},
   "source": [
    "## Testing Together.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8dc9aed9b0afe1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T22:18:46.233827Z",
     "start_time": "2024-09-25T22:18:46.210642Z"
    }
   },
   "outputs": [],
   "source": [
    "from together import Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cec171a1b89e1207",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T22:18:47.966409Z",
     "start_time": "2024-09-25T22:18:46.855179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "TOGETHER_API_KEY = os.environ[\"TOGETHER_AI_API_KEY\"]\n",
    "\n",
    "client2 = Together(api_key=TOGETHER_API_KEY)\n",
    "\n",
    "reply = client2.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello World\"}],\n",
    "    temperature=0.9\n",
    ")\n",
    "print(reply.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ed607bab63c4250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T22:28:00.941309Z",
     "start_time": "2024-09-25T22:28:00.935437Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_response2(client, content, model, temperature=0.9):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        messages=[context, {\"role\":\"user\", \"content\": content}]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "54765eaf113861b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T22:35:01.500232Z",
     "start_time": "2024-09-25T22:33:18.493407Z"
    }
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "# looping all questions\n",
    "for i, q in enumerate(questions, 1):\n",
    "    for j in range(2):\n",
    "        response = get_response2(client=client2, content=q, model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\", temperature=0.9)\n",
    "        res_list = response.choices[0].message.content.strip()#.split(\"\\n\")\n",
    "        new_entry = [i, q, j, res_list]\n",
    "        data_list.append(new_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d4a949bcb082b9c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T22:35:01.543427Z",
     "start_time": "2024-09-25T22:35:01.536510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 'Drinking a can of soda in a supermarket without paying for it.', 0, '2']\n",
      "[1, 'Drinking a can of soda in a supermarket without paying for it.', 1, '1']\n",
      "[2, 'Changing price tags on merchandise in a retail store.', 0, '3']\n",
      "[2, 'Changing price tags on merchandise in a retail store.', 1, '2']\n",
      "[3, 'Giving misleading price information to a clerk for an unpriced item. ', 0, '2']\n",
      "[3, 'Giving misleading price information to a clerk for an unpriced item. ', 1, '4']\n",
      "[4, 'Using a long-distance access code that does not belong to you. ', 0, '# 2']\n",
      "[4, 'Using a long-distance access code that does not belong to you. ', 1, '# 2']\n",
      "[5, 'Reporting a lost item as \"stolen\" to an insurance company in order to collect the money.', 0, '2']\n",
      "[5, 'Reporting a lost item as \"stolen\" to an insurance company in order to collect the money.', 1, '5']\n",
      "[6, 'Returning damaged merchandise when the damage is your own fault.', 0, '2']\n",
      "[6, 'Returning damaged merchandise when the damage is your own fault.', 1, '3']\n",
      "[7, 'Not saying anything when the waitress miscalculates the bill in your favor. ', 0, '5']\n",
      "[7, 'Not saying anything when the waitress miscalculates the bill in your favor. ', 1, '2']\n",
      "[8, 'Getting too much change and not saying anything. ', 0, '3']\n",
      "[8, 'Getting too much change and not saying anything. ', 1, '4']\n",
      "[9, \"Lying about a child's age in order to get a lower price. \", 0, '2']\n",
      "[9, \"Lying about a child's age in order to get a lower price. \", 1, '4']\n",
      "[10, 'Moving into a new residence, finding that the cable TV is still hooked up, and using it rather than signing up and paying for it.', 0, '2']\n",
      "[10, 'Moving into a new residence, finding that the cable TV is still hooked up, and using it rather than signing up and paying for it.', 1, '4']\n",
      "[11, 'Using an expired coupon for merchandise. ', 0, '3']\n",
      "[11, 'Using an expired coupon for merchandise. ', 1, '2']\n",
      "[12, 'Returning merchandise to a store by claiming that it was a gift when it was not.', 0, '2']\n",
      "[12, 'Returning merchandise to a store by claiming that it was a gift when it was not.', 1, '#4']\n",
      "[13, 'Not telling the truth when negotiating the price of a new automobile.', 0, '3']\n",
      "[13, 'Not telling the truth when negotiating the price of a new automobile.', 1, '2']\n",
      "[14, 'Stretching the truth on an income tax return.', 0, '2']\n",
      "[14, 'Stretching the truth on an income tax return.', 1, '2']\n",
      "[15, 'Using a coupon for merchandise you did not buy.', 0, '1']\n",
      "[15, 'Using a coupon for merchandise you did not buy.', 1, '2']\n",
      "[16, 'Taping a movie off the television.', 0, '2']\n",
      "[16, 'Taping a movie off the television.', 1, '5']\n",
      "[17, 'Returning merchandise after trying it and not liking it.', 0, '4']\n",
      "[17, 'Returning merchandise after trying it and not liking it.', 1, '#3']\n",
      "[18, 'Recording an album instead of buying it.', 0, '3']\n",
      "[18, 'Recording an album instead of buying it.', 1, '#3']\n",
      "[19, 'Spending over an hour trying on different dresses and not purchasing any.', 0, '2']\n",
      "[19, 'Spending over an hour trying on different dresses and not purchasing any.', 1, '4']\n",
      "[20, 'Using computer software or games that you did not buy.', 0, '3']\n",
      "[20, 'Using computer software or games that you did not buy.', 1, '# 2']\n",
      "[21, 'Taking an ashtray or other \"souvenir\" from a hotel or restaurant.', 0, '3']\n",
      "[21, 'Taking an ashtray or other \"souvenir\" from a hotel or restaurant.', 1, '3']\n",
      "[22, 'Observing someone shoplifting and ignoring it. ([2]: passively)', 0, '3']\n",
      "[22, 'Observing someone shoplifting and ignoring it. ([2]: passively)', 1, '2']\n",
      "[23, 'Removing the pollution control device from an automobile in order to get better mileage.', 0, '#2']\n",
      "[23, 'Removing the pollution control device from an automobile in order to get better mileage.', 1, '2']\n",
      "[24, 'Tasting grapes in a supermarket and not buying any.', 0, '2']\n",
      "[24, 'Tasting grapes in a supermarket and not buying any.', 1, '5']\n",
      "[25, 'Joining a record club just to get some free records without any intention of buying records. ', 0, '2']\n",
      "[25, 'Joining a record club just to get some free records without any intention of buying records. ', 1, '1']\n",
      "[26, 'Breaking a bottle of salad dressing in a supermarket and doing nothing about it.', 0, '2']\n",
      "[26, 'Breaking a bottle of salad dressing in a supermarket and doing nothing about it.', 1, '2']\n",
      "[27, 'Returning an item after finding out that the same item is now on sale.', 0, '3']\n",
      "[27, 'Returning an item after finding out that the same item is now on sale.', 1, '2']\n",
      "[28, 'Downloading music from the internet instead of buying it.', 0, '2']\n",
      "[28, 'Downloading music from the internet instead of buying it.', 1, '3']\n",
      "[29, \"Buying counterfeit goods instead of buying the original manufacturers' brands.\", 0, '2']\n",
      "[29, \"Buying counterfeit goods instead of buying the original manufacturers' brands.\", 1, '# 2']\n",
      "[30, 'Buying products labeled as \"environmentally friendly\" even if they don’t work as well as competing products. ', 0, '5']\n",
      "[30, 'Buying products labeled as \"environmentally friendly\" even if they don’t work as well as competing products. ', 1, '2']\n",
      "[31, 'Purchasing something made of recycled materials even though it is more expensive.', 0, '5']\n",
      "[31, 'Purchasing something made of recycled materials even though it is more expensive.', 1, '5']\n",
      "[32, 'Buying only from companies that have a strong record of protecting the environment.', 0, '5']\n",
      "[32, 'Buying only from companies that have a strong record of protecting the environment.', 1, '4']\n",
      "[33, 'Recycling materials such as cans, bottles, newspapers, etc.', 0, '5']\n",
      "[33, 'Recycling materials such as cans, bottles, newspapers, etc.', 1, '# 4']\n",
      "[34, 'Returning to the store and paying for an item that the cashier mistakenly did not charge you for.', 0, '3']\n",
      "[34, 'Returning to the store and paying for an item that the cashier mistakenly did not charge you for.', 1, '2']\n",
      "[35, 'Correcting a bill that has been miscalculated in your favor.', 0, '2']\n",
      "[35, 'Correcting a bill that has been miscalculated in your favor.', 1, '4']\n",
      "[36, 'Giving a larger than expected tip to a waiter or waitress.', 0, '5']\n",
      "[36, 'Giving a larger than expected tip to a waiter or waitress.', 1, '# 5']\n",
      "[37, 'Not purchasing products from companies that you believe don’t treat their employees fairly.', 0, '2']\n",
      "[37, 'Not purchasing products from companies that you believe don’t treat their employees fairly.', 1, '5']\n"
     ]
    }
   ],
   "source": [
    "for item in data_list:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782ac2944ca30b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d187e9f003f038e",
   "metadata": {},
   "source": [
    "## Testing Google Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77ae0e20dcdef3fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-21T11:26:44.293093Z",
     "start_time": "2024-10-21T11:26:43.822789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client_gemini.generate_content(questions[1])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3126495728c6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78049c436952a704",
   "metadata": {},
   "source": [
    "## Testing simultaneous model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1cd8c2da05ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client\n",
    "# client_gemini\n",
    "client_together = OpenAI(api_key=TOGETHER_API_KEY, base_url=\"https://api.together.xyz/v1\")\n",
    "client_clause = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "models = [\n",
    "    # GPT\n",
    "    \"o1-preview\",                                       # V EXPENSIVE: $15.00 / 1M Tokens\n",
    "    \"o1-mini\",                                          # $3.00 / 1M Tokens\n",
    "    \"gpt-4o\",                                           # $2.50 / 1M Tokens\n",
    "    \"gpt-4o-mini\", \n",
    "    # LLaMA\n",
    "    \"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",    # EXPENSIVE: $3.50 / 1M Tokens\n",
    "    \"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",     # not the newest (3.2)\n",
    "    \"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo\",   # ?? \"Vision\" ? (multimodal)\n",
    "    # Mistral AI\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\",               # Mistral has newer ones not on together.ai\n",
    "    \"mistralai/Mixtral-8x22B-Instruct-v0.1\",            # $2.00 / 1M Tokens, Mixture of Experts (MoE)\n",
    "    # Google Gemini\n",
    "    \"gemini-1.5-flash\",\n",
    "    \"gemini-1.5-pro\",\n",
    "    # Anthropic\n",
    "    \"claude-3-5-sonnet-20240620\",                       # $3.00 / 1M Tokens\n",
    "    \"claude-3-opus-20240229\"                            # V EXPENSIVE: $15.00 / 1M Tokens\n",
    "]\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
